{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"..\\preprocessing\\county_variables.csv\")\n",
    "num_lag = 5 # number of lag features to predict from\n",
    "\n",
    "data_cols = [col for col in data.columns if col != 'Date']\n",
    "for lag in range(1, num_lag+1):\n",
    "    for col in data_cols:\n",
    "        data[f'{col}_lag{num_lag}'] = data[col].shift(lag)\n",
    "\n",
    "num_targets = 1 # number of forward features to predict\n",
    "for target in range(1, num_targets+1):\n",
    "    for col in data_cols:\n",
    "        data[f'{col}_target{target}'] = data[col].shift(-target)\n",
    "\n",
    "# time input features\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['doy'] = data['Date'].dt.day_of_year\n",
    "data['cos_doy'] = np.cos(2*np.pi*data['Date'].dt.day_of_year/365.25)\n",
    "data['sin_doy'] = np.sin(2*np.pi*data['Date'].dt.day_of_year/365.25)\n",
    "\n",
    "data = data.iloc[num_lag:-num_targets]\n",
    "\n",
    "total_data_points = len(data.index)\n",
    "training_data_pct = 0.8\n",
    "training_data = data.iloc[:int(training_data_pct * total_data_points)]\n",
    "testing_data = data.iloc[int(training_data_pct * total_data_points):]\n",
    "\n",
    "training_data.to_csv('training.csv', index=False)\n",
    "testing_data.to_csv('testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = [col for col in training_data.columns if ('target' not in col and col != 'Date')]\n",
    "output_features = [col for col in training_data.columns if ('target' in col and col != 'Date')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ReLU\n",
    "from tensorflow.keras.activations import sigmoid, relu, linear, leaky_relu\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture of deep neural network\n",
    "model = Sequential(name='WeatherModel')\n",
    "\n",
    "model.add(Input((len(input_features),)))\n",
    "\n",
    "layer_sizes = [512, 784, 784, 512, 256]\n",
    "#activation = leaky_relu\n",
    "\n",
    "for layer_size in layer_sizes:\n",
    "    model.add(Dense(layer_size))\n",
    "    model.add(ReLU(negative_slope=0.5))\n",
    "\n",
    "model.add(Dense(len(output_features)))\n",
    "model.add(ReLU(negative_slope=0.5))\n",
    "\n",
    "#model.summary()\n",
    "model.compile(loss='mse', optimizer='adam')#, metrics = ['root_mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_data[input_features], training_data[output_features], epochs=500, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(testing_data[input_features], testing_data[output_features])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
